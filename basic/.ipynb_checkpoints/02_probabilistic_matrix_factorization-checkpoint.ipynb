{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import logging\n",
    "import theano\n",
    "import scipy as sp\n",
    "from theano import tensor as tt\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF():\n",
    "    \n",
    "    def __init__(self, train, dim , alpha=2, std=0.01, bounds=(1,5)):\n",
    "        self.dim = dim # latent dimension\n",
    "        self.alpha = alpha # likeihood variance : sigma\n",
    "        self.std = np.sqrt(1/alpha) # \n",
    "        self.bounds = bounds\n",
    "        self.data = train.copy()\n",
    "        n, m = self.data.shape \n",
    "        \n",
    "        nan_mask = np.isnan(self.data) # missing mask\n",
    "        self.data[nan_mask] = self.data[~nan_mask].mean() # 평균값으로 nan 값 채워넣음\n",
    "        \n",
    "        self.alpha_u = 1/ self.data.var(axis=1).mean() # u 분산 평균\n",
    "        self.alpha_v = 1/ self.data.var(axis=0).mean() # v 분산 평균\n",
    "        \n",
    "        logging.info('building the PMF model')\n",
    "        with pm.Model() as pmf:\n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            U = pm.MvNormal('U', mu = 0, tau = self.alpha_u * np.eye(dim),\n",
    "                           shape = (n,dim), testval = np.random.randn(n,dim) * std)\n",
    "            V = pm.MvNormal('V', mu = 0, tau = self.alpha_v * np.eye(dim),\n",
    "                            shape = (m,dim), testval=np.random.randn(m,dim)*std)\n",
    "            R = pm.Normal(\n",
    "                'R', mu= tt.dot(U, V.T)[~nan_mask], tau=self.alpha,\n",
    "                observed=self.data[~nan_mask])\n",
    "    \n",
    "        logging.info('done building the PMF model')\n",
    "        self.model = pmf\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_map(self):\n",
    "    tstart = time.time()\n",
    "    with self.model:\n",
    "        logging.info('finding PMF MAP using L-bfgs-b optimization...')\n",
    "        self._map = pm.find_MAP(method='L-BFGS-B')\n",
    "    elapsed = int(time.time()- tstart)\n",
    "    logging.info('found PMF MAP in %d seconds'% elapsed)\n",
    "    return self._map\n",
    "\n",
    "def _map(self):\n",
    "    try:\n",
    "        return self._map\n",
    "    except :\n",
    "        return self.find_map()\n",
    "    \n",
    "PMF.find_map = _find_map\n",
    "PMF.map = property(_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_samples(self, **kwargs):\n",
    "    kwargs.setdefault('chains', 1)\n",
    "    with self.model:\n",
    "        self.trace =pm.sample(**kwargs)\n",
    "PMF.draw_samples = _draw_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict(self, U, V):\n",
    "    R = np.dot(U, V.T)\n",
    "    n,m = R.shape\n",
    "    sample_R = np.random.normal(R, self.std) # \n",
    "    \n",
    "    low, high = self.bounds\n",
    "    sample_R[sample_R< low] = low\n",
    "    sample_R[sample_R> high] = high\n",
    "    return sample_R\n",
    "PMF.predict = _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(test_data, predicted):\n",
    "    I = ~np.isnan(test_data)\n",
    "    N = I.sum()\n",
    "    sqerror = abs(test_data - predicted)**2\n",
    "    mse = sqerror[I].sum()/N\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, percent_test=0.1):\n",
    "    n, m = data.shape\n",
    "    N = n * m\n",
    "    \n",
    "    train = data.copy()\n",
    "    test = np.ones(data.shape) * np.nan\n",
    "    \n",
    "    tosample = np.where(~np.isnan(train)) \n",
    "    idx_pairs = list(zip(tosample[0], tosample[1]))\n",
    "    \n",
    "    test_size = int(len(idx_pairs) * percent_test)\n",
    "    train_size = len(idx_pairs)- test_size\n",
    "    \n",
    "    indices = np.arange(len(idx_pairs))\n",
    "    sample = np.random.choice(indices, replace=False, size=test_size)\n",
    "    \n",
    "    for idx in sample:\n",
    "        idx_pair = idx_pairs[idx]\n",
    "        test[idx_pair] = train[idx_pair]  # transfer to test set\n",
    "        train[idx_pair] = np.nan          # remove from train set\n",
    "\n",
    "    # Verify everything worked properly\n",
    "    assert(train_size == N-np.isnan(train).sum())\n",
    "    assert(test_size == N-np.isnan(test).sum())\n",
    "\n",
    "    # Return train set and test set\n",
    "    return train, test\n",
    "\n",
    "train, test = split_train_test(dense_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 2\n",
    "DIM = 10\n",
    "pmf = PMF(train, DIM, ALPHA, std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf.find_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_map(pmf_model, train, test):\n",
    "    U = pmf_model.map['U']\n",
    "    V = pmf_model.map['V']\n",
    "\n",
    "    # Make predictions and calculate RMSE on train & test sets.\n",
    "    predictions = pmf_model.predict(U, V)\n",
    "    train_rmse = rmse(train, predictions)\n",
    "    test_rmse = rmse(test, predictions)\n",
    "    overfit = test_rmse - train_rmse\n",
    "\n",
    "    # Print report.\n",
    "    print('PMF MAP training RMSE: %.5f' % train_rmse)\n",
    "    print('PMF MAP testing RMSE:  %.5f' % test_rmse)\n",
    "    print('Train/test difference: %.5f' % overfit)\n",
    "\n",
    "    return test_rmse\n",
    "\n",
    "\n",
    "# Add eval function to PMF class.\n",
    "PMF.eval_map = eval_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_map_rmse = pmf.eval_map(train, test)\n",
    "pmf_improvement = baselines['mom'] - pmf_map_rmse\n",
    "print('PMF MAP Improvement:   %.5f' % pmf_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf.draw_samples(draws=500, tune=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norms(pmf_model, monitor=('U', 'V'), ord='fro'):\n",
    "    \"\"\"Return norms of latent variables at each step in the\n",
    "    sample trace. These can be used to monitor convergence\n",
    "    of the sampler.\n",
    "    \"\"\"\n",
    "    monitor = ('U', 'V')\n",
    "    norms = {var: [] for var in monitor}\n",
    "    for sample in pmf_model.trace:\n",
    "        for var in monitor:\n",
    "            norms[var].append(np.linalg.norm(sample[var], ord))\n",
    "    return norms\n",
    "\n",
    "\n",
    "def _traceplot(pmf_model):\n",
    "    \"\"\"Plot Frobenius norms of U and V as a function of sample #.\"\"\"\n",
    "    trace_norms = pmf_model.norms()\n",
    "    u_series = pd.Series(trace_norms['U'])\n",
    "    v_series = pd.Series(trace_norms['V'])\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    u_series.plot(kind='line', ax=ax1, grid=False,\n",
    "                  title=\"$\\|U\\|_{Fro}^2$ at Each Sample\")\n",
    "    v_series.plot(kind='line', ax=ax2, grid=False,\n",
    "                  title=\"$\\|V\\|_{Fro}^2$ at Each Sample\")\n",
    "    ax1.set_xlabel(\"Sample Number\")\n",
    "    ax2.set_xlabel(\"Sample Number\")\n",
    "\n",
    "\n",
    "PMF.norms = _norms\n",
    "PMF.traceplot = _traceplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf.traceplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _running_rmse(pmf_model, test_data, train_data, burn_in=0, plot=True):\n",
    "    \"\"\"Calculate RMSE for each step of the trace to monitor convergence.\n",
    "    \"\"\"\n",
    "    burn_in = burn_in if len(pmf_model.trace) >= burn_in else 0\n",
    "    results = {'per-step-train': [], 'running-train': [],\n",
    "               'per-step-test': [], 'running-test': []}\n",
    "    R = np.zeros(test_data.shape)\n",
    "    for cnt, sample in enumerate(pmf_model.trace[burn_in:]):\n",
    "        sample_R = pmf_model.predict(sample['U'], sample['V'])\n",
    "        R += sample_R\n",
    "        running_R = R / (cnt + 1)\n",
    "        results['per-step-train'].append(rmse(train_data, sample_R))\n",
    "        results['running-train'].append(rmse(train_data, running_R))\n",
    "        results['per-step-test'].append(rmse(test_data, sample_R))\n",
    "        results['running-test'].append(rmse(test_data, running_R))\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    if plot:\n",
    "        results.plot(\n",
    "            kind='line', grid=False, figsize=(15, 7),\n",
    "            title='Per-step and Running RMSE From Posterior Predictive')\n",
    "\n",
    "    # Return the final predictions, and the RMSE calculations\n",
    "    return running_R, results\n",
    "\n",
    "\n",
    "PMF.running_rmse = _running_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, results = pmf.running_rmse(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And our final RMSE?\n",
    "final_test_rmse = results['running-test'].values[-1]\n",
    "final_train_rmse = results['running-train'].values[-1]\n",
    "print('Posterior predictive train RMSE: %.5f' % final_train_rmse)\n",
    "print('Posterior predictive test RMSE:  %.5f' % final_test_rmse)\n",
    "print('Train/test difference:           %.5f' % (final_test_rmse - final_train_rmse))\n",
    "print('Improvement from MAP:            %.5f' % (pmf_map_rmse - final_test_rmse))\n",
    "print('Improvement from Mean of Means:  %.5f' % (baselines['mom'] - final_test_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
