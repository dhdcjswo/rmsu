{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/movie.data', sep='\\t', names=[\"userid\", \"itemid\", \"rating\", \"timestamp\"])\n",
    "\n",
    "movie_columns  = ['movie id', 'movie title', 'release date', 'video release date', 'IMDb URL',\n",
    "                  'unknown','Action','Adventure', 'Animation',\"Children's\", 'Comedy', 'Crime',\n",
    "                  'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "                  'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "movies = pd.read_csv('../data/u.item', sep='|', names=movie_columns , encoding='latin-1',index_col=\"movie id\",parse_dates=['release date'])\n",
    "ratings = data.rating # 영화 ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "추천 알고리즘의 성능을 평가하기 위한 베이스라인들을 정리. \n",
    "\n",
    "\n",
    "\n",
    "### 1.Uniform Random\n",
    "모든 결측치를 주어진 데이터의 최소, 최대값 사이에서 random하게 뽑은 값으로 보간\n",
    "\n",
    "$$\n",
    "R_{ij}  \\sim Uniform(1,5)\n",
    "$$\n",
    "\n",
    "### 2. Global Mean\n",
    "관측된 데이터들의 전체 평균 평점으로 결측치를 보간\n",
    "\n",
    "$$\n",
    "Global \\space mean = \\frac {1} {n} \\frac {1} {m} \\sum^n_i \\sum^m_j I_{ij}R_{ij} \\\\\n",
    "R_{ij} = Global \\space mean\n",
    "$$\n",
    "\n",
    "### 3. Mean of Means \n",
    "유저에 따라서 평점이 전반적으로 높을수도 낮을수도 있음 : 개인적인 특징   \n",
    "영화에 따라서 평점이 다를 것. 좋은영화라면 전반적으로 높은 평점을 그렇지 않다면 낮은평점이 책정될 것 : 영화의 특징  \n",
    "유저와 영화의 특징과 전체 평점을 평균하여 결측치를 보간\n",
    "\n",
    "$$\n",
    "user \\space mean = \\frac {1} {n} \\sum^n_i I_{ij}R_{ij} \\\\\n",
    "movie \\space mean = \\frac {1} {m} \\sum^m_j I_{ij}R_{ij} \\\\\n",
    "R = \\frac {1} {3} ( user \\space mean_j + movie \\space mean_i + Global \\space mean)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline():\n",
    "    \"\"\"Calculate baseline predictions.\"\"\"\n",
    "\n",
    "    def __init__(self, train_data):\n",
    "        \"\"\"Simple heuristic-based transductive learning to fill in missing\n",
    "        values in data matrix.\"\"\"\n",
    "        self.predict(train_data.copy())\n",
    "\n",
    "    def predict(self, train_data):\n",
    "        raise NotImplementedError(\n",
    "            'baseline prediction not implemented for base class')\n",
    "\n",
    "    def rmse(self, test_data):\n",
    "        \"\"\"Calculate root mean squared error for predictions on test data.\"\"\"\n",
    "        I = ~np.isnan(test_data)   # indicator for missing values\n",
    "        N = I.sum()                # number of non-missing values\n",
    "        sqerror = abs(test_data - self.predicted) ** 2  # squared error array\n",
    "        mse = sqerror[I].sum() / N                 # mean squared error\n",
    "        return np.sqrt(mse)      \n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return split_title(self.__class__.__name__)\n",
    "\n",
    "\n",
    "# Implement the 3 baselines.\n",
    "\n",
    "class UniformRandomBaseline(Baseline):\n",
    "    \"\"\"결측치를 random하게 샘플링한 값으로 보간\"\"\"\n",
    "\n",
    "    def predict(self, train_data):\n",
    "        nan_mask = np.isnan(train_data)\n",
    "        masked_train = np.ma.masked_array(train_data, nan_mask)\n",
    "        pmin, pmax = masked_train.min(), masked_train.max()\n",
    "        N = nan_mask.sum()\n",
    "        train_data[nan_mask] = np.random.uniform(pmin, pmax, N)\n",
    "        self.predicted = train_data\n",
    "\n",
    "\n",
    "class GlobalMeanBaseline(Baseline):\n",
    "    \"\"\"결측치를 전체 평균 값으로 보간\"\"\"\n",
    "\n",
    "    def predict(self, train_data):\n",
    "        nan_mask = np.isnan(train_data)\n",
    "        train_data[nan_mask] = train_data[~nan_mask].mean()\n",
    "        self.predicted = train_data\n",
    "\n",
    "\n",
    "class MeanOfMeansBaseline(Baseline):\n",
    "    \"\"\"결측치를 유저평균,영화평균,전체평균의 평균값으로 채움\"\"\"\n",
    "\n",
    "    def predict(self, train_data):\n",
    "        nan_mask = np.isnan(train_data)\n",
    "        masked_train = np.ma.masked_array(train_data, nan_mask)\n",
    "        global_mean = masked_train.mean()\n",
    "        user_means = masked_train.mean(axis=1)\n",
    "        item_means = masked_train.mean(axis=0)\n",
    "        self.predicted = train_data.copy()\n",
    "        n, m = train_data.shape\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if np.ma.isMA(item_means[j]):\n",
    "                    self.predicted[i, j] = np.mean(\n",
    "                        (global_mean, user_means[i]))\n",
    "                else:\n",
    "                    self.predicted[i, j] = np.mean(\n",
    "                        (global_mean, user_means[i], item_means[j]))\n",
    "\n",
    "\n",
    "baseline_methods = {}\n",
    "baseline_methods['ur'] = UniformRandomBaseline\n",
    "baseline_methods['gm'] = GlobalMeanBaseline\n",
    "baseline_methods['mom'] = MeanOfMeansBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, percent_test=0.1):\n",
    "    \"\"\"Split the data into train/test sets.\n",
    "    :param int percent_test: Percentage of data to use for testing. Default 10.\n",
    "    \"\"\"\n",
    "    n, m = data.shape             # # users, # movies\n",
    "    N = n * m                     # # cells in matrix\n",
    "\n",
    "    # Prepare train/test ndarrays.\n",
    "    train = data.copy()\n",
    "    test = np.ones(data.shape) * np.nan\n",
    "\n",
    "    # Draw random sample of training data to use for testing.\n",
    "    tosample = np.where(~np.isnan(train))       # 샘플링 대상은 존재하는 값들. 인덱스\n",
    "    idx_pairs = list(zip(tosample[0], tosample[1]))   # 존재하는 값 인덱스\n",
    "\n",
    "    test_size = int(len(idx_pairs) * percent_test)  # test 크기\n",
    "    train_size = len(idx_pairs) - test_size   # train 크기\n",
    "\n",
    "    indices = np.arange(len(idx_pairs))         #  존재하는 값의 총 길이에 대한 idnex\n",
    "    sample = np.random.choice(indices, replace=False, size=test_size) # 테스트 길이만큼의 인덱스 샘플링.\n",
    "\n",
    "    # random sample을 이용해 test set 채우기\n",
    "    for idx in sample:\n",
    "        idx_pair = idx_pairs[idx]\n",
    "        test[idx_pair] = train[idx_pair]  # train 값을 test값에 대입\n",
    "        train[idx_pair] = np.nan          # train 값은 제거\n",
    "\n",
    "    # 잘 나뉘어 졌는지 확인\n",
    "    assert(train_size == N-np.isnan(train).sum())\n",
    "    assert(test_size == N-np.isnan(test).sum())\n",
    "\n",
    "    # Return train set and test set\n",
    "    return train, test\n",
    "\n",
    "train, test = split_train_test(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Random Baseline RMSE:\t1.70544\n",
      "Global Mean Baseline RMSE:\t1.12748\n",
      "Mean Of Means Baseline RMSE:\t1.01826\n"
     ]
    }
   ],
   "source": [
    "baselines = {}\n",
    "for name in baseline_methods:\n",
    "    Method = baseline_methods[name]\n",
    "    method = Method(train)\n",
    "    baselines[name] = method.rmse(test)\n",
    "    print('%s RMSE:\\t%.5f' % (method, baselines[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## refrence\n",
    "https://docs.pymc.io/notebooks/probabilistic_matrix_factorization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
