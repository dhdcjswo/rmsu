{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import logging\n",
    "import theano\n",
    "import scipy as sp\n",
    "from theano import tensor as tt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/movie.data', sep='\\t', names=[\"userid\", \"itemid\", \"rating\", \"timestamp\"])\n",
    "\n",
    "movie_columns  = ['movie id', 'movie title', 'release date', 'video release date', 'IMDb URL',\n",
    "                  'unknown','Action','Adventure', 'Animation',\"Children's\", 'Comedy', 'Crime',\n",
    "                  'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "                  'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "movies = pd.read_csv('../data/u.item', sep='|', names=movie_columns , encoding='latin-1',index_col=\"movie id\",parse_dates=['release date'])\n",
    "ratings = data.rating # 영화 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.pivot_table('rating', index='userid', columns='itemid').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF():\n",
    "    \n",
    "    def __init__(self, train, dim , alpha=2, std=0.01, bounds=(1,5)):\n",
    "        self.dim = dim # latent dimension\n",
    "        self.alpha = alpha # likeihood variance : sigma\n",
    "        self.std = np.sqrt(1/alpha) # \n",
    "        self.bounds = bounds\n",
    "        self.data = train.copy()\n",
    "        n, m = self.data.shape \n",
    "        \n",
    "        nan_mask = np.isnan(self.data) # missing mask\n",
    "        self.data[nan_mask] = self.data[~nan_mask].mean() # 평균값으로 nan 값 채워넣음\n",
    "        \n",
    "        self.alpha_u = 1/ self.data.var(axis=1).mean() # u 분산 평균\n",
    "        self.alpha_v = 1/ self.data.var(axis=0).mean() # v 분산 평균\n",
    "        \n",
    "        logging.info('building the PMF model')\n",
    "        with pm.Model() as pmf:\n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            U = pm.MvNormal('U', mu = 0, tau = self.alpha_u * np.eye(dim),\n",
    "                           shape = (n,dim), testval = np.random.randn(n,dim) * std)\n",
    "            V = pm.MvNormal('V', mu = 0, tau = self.alpha_v * np.eye(dim),\n",
    "                            shape = (m,dim), testval=np.random.randn(m,dim)*std)\n",
    "            R = pm.Normal(\n",
    "                'R', mu= tt.dot(U, V.T)[~nan_mask], tau=self.alpha,\n",
    "                observed=self.data[~nan_mask])\n",
    "    \n",
    "        logging.info('done building the PMF model')\n",
    "        self.model = pmf\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_map(self):\n",
    "    tstart = time.time()\n",
    "    with self.model:\n",
    "        logging.info('finding PMF MAP using L-bfgs-b optimization...')\n",
    "        self._map = pm.find_MAP(method='L-BFGS-B')\n",
    "    elapsed = int(time.time()- tstart)\n",
    "    logging.info('found PMF MAP in %d seconds'% elapsed)\n",
    "    return self._map\n",
    "\n",
    "def _map(self):\n",
    "    try:\n",
    "        return self._map\n",
    "    except :\n",
    "        return self.find_map()\n",
    "    \n",
    "PMF.find_map = _find_map\n",
    "PMF.map = property(_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_samples(self, **kwargs):\n",
    "    kwargs.setdefault('chains', 1)\n",
    "    with self.model:\n",
    "        self.trace =pm.sample(**kwargs)\n",
    "PMF.draw_samples = _draw_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict(self, U, V):\n",
    "    R = np.dot(U, V.T)\n",
    "    n,m = R.shape\n",
    "    sample_R = np.random.normal(R, self.std) # \n",
    "    \n",
    "    low, high = self.bounds\n",
    "    sample_R[sample_R< low] = low\n",
    "    sample_R[sample_R> high] = high\n",
    "    return sample_R\n",
    "PMF.predict = _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(test_data, predicted):\n",
    "    I = ~np.isnan(test_data)\n",
    "    N = I.sum()\n",
    "    sqerror = abs(test_data - predicted)**2\n",
    "    mse = sqerror[I].sum()/N\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, percent_test=0.1):\n",
    "    n, m = data.shape\n",
    "    N = n * m\n",
    "    \n",
    "    train = data.copy()\n",
    "    test = np.ones(data.shape) * np.nan\n",
    "    \n",
    "    tosample = np.where(~np.isnan(train)) \n",
    "    idx_pairs = list(zip(tosample[0], tosample[1]))\n",
    "    \n",
    "    test_size = int(len(idx_pairs) * percent_test)\n",
    "    train_size = len(idx_pairs)- test_size\n",
    "    \n",
    "    indices = np.arange(len(idx_pairs))\n",
    "    sample = np.random.choice(indices, replace=False, size=test_size)\n",
    "    \n",
    "    for idx in sample:\n",
    "        idx_pair = idx_pairs[idx]\n",
    "        test[idx_pair] = train[idx_pair]  # transfer to test set\n",
    "        train[idx_pair] = np.nan          # remove from train set\n",
    "\n",
    "    # Verify everything worked properly\n",
    "    assert(train_size == N-np.isnan(train).sum())\n",
    "    assert(test_size == N-np.isnan(test).sum())\n",
    "\n",
    "    # Return train set and test set\n",
    "    return train, test\n",
    "\n",
    "train, test = split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:building the PMF model\n",
      "C:\\Users\\dhdcj\\AppData\\Roaming\\Python\\Python37\\site-packages\\theano\\tensor\\subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "INFO:root:done building the PMF model\n"
     ]
    }
   ],
   "source": [
    "ALPHA = 2\n",
    "DIM = 10\n",
    "pmf = PMF(train, DIM, ALPHA, std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finding PMF MAP using L-bfgs-b optimization...\n",
      "C:\\Users\\dhdcj\\AppData\\Roaming\\Python\\Python37\\site-packages\\pymc3\\tuning\\starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.\n",
      "  warnings.warn('find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.')\n",
      "  0%|                                                                                         | 0/5000 [00:00<?, ?it/s]C:\\Users\\dhdcj\\AppData\\Roaming\\Python\\Python37\\site-packages\\theano\\tensor\\subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "logp = -1.5355e+05, ||grad|| = 1.0822: 100%|█████████████████████████████████████████| 553/553 [01:09<00:00,  7.91it/s]\n",
      "INFO:root:found PMF MAP in 101 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'U': array([[ 0.82505808, -1.45492477,  0.05392429, ...,  0.14327027,\n",
       "          0.16780184, -0.29148398],\n",
       "        [ 0.01519386, -1.22141107, -0.20036465, ...,  0.51351686,\n",
       "          0.40611433, -0.28093899],\n",
       "        [ 0.3733684 , -1.29511723,  0.02166351, ...,  0.44597149,\n",
       "          0.08276389,  0.02716791],\n",
       "        ...,\n",
       "        [ 0.20036194, -0.96898937,  0.20793147, ...,  0.51368997,\n",
       "          0.09223361, -0.42661118],\n",
       "        [-0.50060905, -1.28093761, -0.30659359, ...,  1.15503589,\n",
       "          0.00503589, -0.19902283],\n",
       "        [-0.18513846, -1.30110614, -0.32309749, ...,  0.02112201,\n",
       "         -0.07602124, -0.89652119]]),\n",
       " 'V': array([[ 0.03241338, -1.12977888,  0.140434  , ...,  0.9328965 ,\n",
       "         -0.11263378, -1.04692399],\n",
       "        [-0.34222624, -0.96291915,  0.11415688, ...,  0.59545962,\n",
       "         -0.06977058, -0.66270539],\n",
       "        [-0.12706489, -0.93052194, -0.47305359, ...,  0.12968848,\n",
       "         -0.03594224,  0.74588257],\n",
       "        ...,\n",
       "        [-0.00217322, -0.17472074, -0.07904756, ..., -0.15388035,\n",
       "          0.02332941,  0.0231807 ],\n",
       "        [ 0.10066453, -0.28921986, -0.21458332, ...,  0.19855144,\n",
       "         -0.17606079, -0.06329823],\n",
       "        [ 0.17305197, -0.27859262, -0.05033614, ...,  0.10133546,\n",
       "          0.07429839,  0.05349664]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf.find_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_map(pmf_model, train, test):\n",
    "    U = pmf_model.map['U']\n",
    "    V = pmf_model.map['V']\n",
    "\n",
    "    # Make predictions and calculate RMSE on train & test sets.\n",
    "    predictions = pmf_model.predict(U, V)\n",
    "    train_rmse = rmse(train, predictions)\n",
    "    test_rmse = rmse(test, predictions)\n",
    "    overfit = test_rmse - train_rmse\n",
    "\n",
    "    # Print report.\n",
    "    print('PMF MAP training RMSE: %.5f' % train_rmse)\n",
    "    print('PMF MAP testing RMSE:  %.5f' % test_rmse)\n",
    "    print('Train/test difference: %.5f' % overfit)\n",
    "\n",
    "    return test_rmse\n",
    "\n",
    "\n",
    "# Add eval function to PMF class.\n",
    "PMF.eval_map = eval_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 1.00948\n",
      "PMF MAP testing RMSE:  1.13847\n",
      "Train/test difference: 0.12899\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'baselines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7d17e33df5e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpmf_map_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpmf_improvement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mom'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpmf_map_rmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PMF MAP Improvement:   %.5f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpmf_improvement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'baselines' is not defined"
     ]
    }
   ],
   "source": [
    "pmf_map_rmse = pmf.eval_map(train, test)\n",
    "pmf_improvement = baselines['mom'] - pmf_map_rmse\n",
    "print('PMF MAP Improvement:   %.5f' % pmf_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymc3:Auto-assigning NUTS sampler...\n",
      "INFO:pymc3:Initializing NUTS using jitter+adapt_diag...\n",
      "C:\\Users\\dhdcj\\AppData\\Roaming\\Python\\Python37\\site-packages\\theano\\tensor\\subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "INFO:pymc3:Sequential sampling (1 chains in 1 job)\n",
      "INFO:pymc3:NUTS: [V, U]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [2:03:18<00:00,  5.12s/it]\n",
      "INFO:pymc3:Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    }
   ],
   "source": [
    "pmf.draw_samples(draws=500, tune=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norms(pmf_model, monitor=('U', 'V'), ord='fro'):\n",
    "    \"\"\"Return norms of latent variables at each step in the\n",
    "    sample trace. These can be used to monitor convergence\n",
    "    of the sampler.\n",
    "    \"\"\"\n",
    "    monitor = ('U', 'V')\n",
    "    norms = {var: [] for var in monitor}\n",
    "    for sample in pmf_model.trace:\n",
    "        for var in monitor:\n",
    "            norms[var].append(np.linalg.norm(sample[var], ord))\n",
    "    return norms\n",
    "\n",
    "\n",
    "def _traceplot(pmf_model):\n",
    "    \"\"\"Plot Frobenius norms of U and V as a function of sample #.\"\"\"\n",
    "    trace_norms = pmf_model.norms()\n",
    "    u_series = pd.Series(trace_norms['U'])\n",
    "    v_series = pd.Series(trace_norms['V'])\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    u_series.plot(kind='line', ax=ax1, grid=False,\n",
    "                  title=\"$\\|U\\|_{Fro}^2$ at Each Sample\")\n",
    "    v_series.plot(kind='line', ax=ax2, grid=False,\n",
    "                  title=\"$\\|V\\|_{Fro}^2$ at Each Sample\")\n",
    "    ax1.set_xlabel(\"Sample Number\")\n",
    "    ax2.set_xlabel(\"Sample Number\")\n",
    "\n",
    "\n",
    "PMF.norms = _norms\n",
    "PMF.traceplot = _traceplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf.traceplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _running_rmse(pmf_model, test_data, train_data, burn_in=0, plot=True):\n",
    "    \"\"\"Calculate RMSE for each step of the trace to monitor convergence.\n",
    "    \"\"\"\n",
    "    burn_in = burn_in if len(pmf_model.trace) >= burn_in else 0\n",
    "    results = {'per-step-train': [], 'running-train': [],\n",
    "               'per-step-test': [], 'running-test': []}\n",
    "    R = np.zeros(test_data.shape)\n",
    "    for cnt, sample in enumerate(pmf_model.trace[burn_in:]):\n",
    "        sample_R = pmf_model.predict(sample['U'], sample['V'])\n",
    "        R += sample_R\n",
    "        running_R = R / (cnt + 1)\n",
    "        results['per-step-train'].append(rmse(train_data, sample_R))\n",
    "        results['running-train'].append(rmse(train_data, running_R))\n",
    "        results['per-step-test'].append(rmse(test_data, sample_R))\n",
    "        results['running-test'].append(rmse(test_data, running_R))\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    if plot:\n",
    "        results.plot(\n",
    "            kind='line', grid=False, figsize=(15, 7),\n",
    "            title='Per-step and Running RMSE From Posterior Predictive')\n",
    "\n",
    "    # Return the final predictions, and the RMSE calculations\n",
    "    return running_R, results\n",
    "\n",
    "\n",
    "PMF.running_rmse = _running_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, results = pmf.running_rmse(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And our final RMSE?\n",
    "final_test_rmse = results['running-test'].values[-1]\n",
    "final_train_rmse = results['running-train'].values[-1]\n",
    "print('Posterior predictive train RMSE: %.5f' % final_train_rmse)\n",
    "print('Posterior predictive test RMSE:  %.5f' % final_test_rmse)\n",
    "print('Train/test difference:           %.5f' % (final_test_rmse - final_train_rmse))\n",
    "print('Improvement from MAP:            %.5f' % (pmf_map_rmse - final_test_rmse))\n",
    "print('Improvement from Mean of Means:  %.5f' % (baselines['mom'] - final_test_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
